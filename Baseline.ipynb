{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50ff06d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import collections\n",
    "import re, string\n",
    "import sys\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82280ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "def init_dataset(json) -> tuple[dict, list]:\n",
    "    ds: dict = {}\n",
    "    keys = json.keys()\n",
    "    for k in keys:\n",
    "        ds[k] = []\n",
    "    return ds, keys\n",
    "\n",
    "def read_json(file) -> pd.DataFrame:\n",
    "    dataset = {}\n",
    "    keys = []\n",
    "    with open(file) as file_lines:\n",
    "        for count, line in enumerate(file_lines):\n",
    "            json_line = json.loads(line.strip())\n",
    "            if count == 0:\n",
    "                dataset, keys = init_dataset(json_line)\n",
    "            for k in keys:\n",
    "                dataset[k].append(json_line[k])\n",
    "        return pd.DataFrame(dataset)\n",
    "\n",
    "def read_csv(file) -> pd.DataFrame:\n",
    "    dataset = {}\n",
    "    with open(file, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        keys = reader.fieldnames\n",
    "        for k in keys:\n",
    "            dataset[k] = []\n",
    "        for row in reader:\n",
    "            for k in keys:\n",
    "                dataset[k].append(row[k])\n",
    "    return pd.DataFrame(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc0257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yelp_review = read_json('data/yelp_academic_dataset_review.json')\n",
    "yelp_review = read_csv('data/yelp_academic_dataset_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02e0a185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yelp_business = read_json('data/yelp_academic_dataset_business.json')\n",
    "yelp_business = read_csv('data/yelp_academic_dataset_business.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd32bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data: Restaurants reviewed by karen, the user with the most reviews\n",
    "# Businesses that are categorized as restaurants\n",
    "business_restaurant = yelp_business.loc[yelp_business['categories'].str.contains('Restaurant', na=False)]\n",
    "# Reviews of Restaurant businesses\n",
    "review_restaurant = yelp_review[yelp_review['business_id'].isin(business_restaurant['business_id'])]\n",
    "# User with most restaurant reviews\n",
    "karen = review_restaurant['user_id'].value_counts().index[0]\n",
    "# Reviews Karen has made of restaurant businesses\n",
    "review_restaurant_karen = review_restaurant.loc[review_restaurant['user_id'] == karen]\n",
    "# Restaurant businesses that Karen has reviewed\n",
    "business_restaurant_karen = business_restaurant[business_restaurant['business_id'].isin(review_restaurant_karen['business_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b52787",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean Data: remove missing rows and irrelevant columns\n",
    "df = business_restaurant_karen.set_index('business_id')\n",
    "\n",
    "# Remove columns with greater than 20% missing fields\n",
    "mask = df.applymap(lambda x: x =='' or x == 'None').sum()\n",
    "features = ((mask/len(df)) * 100).map(lambda x: x < 20)\n",
    "\n",
    "\n",
    "# Remove non-attribute columns (except business_id)\n",
    "features.loc[~features.index.str.contains('attributes.')] = False\n",
    "#features.loc['business_id'] = True\n",
    "dataset = df.loc[:, features]\n",
    "\n",
    "# Remove rows with missing data\n",
    "mask = dataset.applymap(lambda x: x == '' or x == 'None')\n",
    "dataset = dataset.loc[~mask.any(axis=1)]\n",
    "\n",
    "# Remove all non-boolean columns\n",
    "mask = dataset.applymap(lambda x : x == 'True' or x == 'False').sum() != 0\n",
    "#mask.loc['business_id'] = True\n",
    "#dataset = dataset.set_index('business_id')\n",
    "dataset = dataset.loc[:, mask].applymap(lambda x: x == 'True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ebaeb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Data: add targets\n",
    "df = review_restaurant_karen.set_index('business_id')\n",
    "df = df.loc[df.index.intersection(dataset.index)]\n",
    "df = df.astype({'stars':'float'})\n",
    "dataset['target'] = df.groupby(df.index)['stars'].mean().map(lambda x: x > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1be3cd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.210467</td>\n",
       "      <td>0.262052</td>\n",
       "      <td>-0.367110</td>\n",
       "      <td>1.045168</td>\n",
       "      <td>-0.385329</td>\n",
       "      <td>-0.685348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.418842</td>\n",
       "      <td>0.518833</td>\n",
       "      <td>-1.023205</td>\n",
       "      <td>1.438368</td>\n",
       "      <td>0.205112</td>\n",
       "      <td>-0.539704</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.623524</td>\n",
       "      <td>0.588470</td>\n",
       "      <td>-0.410550</td>\n",
       "      <td>1.551780</td>\n",
       "      <td>0.218564</td>\n",
       "      <td>-0.442690</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.337595</td>\n",
       "      <td>0.894654</td>\n",
       "      <td>-1.002048</td>\n",
       "      <td>0.903907</td>\n",
       "      <td>0.279202</td>\n",
       "      <td>-0.834362</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.294439</td>\n",
       "      <td>0.635720</td>\n",
       "      <td>-1.114369</td>\n",
       "      <td>1.191932</td>\n",
       "      <td>-0.393770</td>\n",
       "      <td>-0.703637</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>1.334870</td>\n",
       "      <td>0.145165</td>\n",
       "      <td>-0.275946</td>\n",
       "      <td>1.291604</td>\n",
       "      <td>0.213553</td>\n",
       "      <td>-0.521416</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>0.593154</td>\n",
       "      <td>-0.358526</td>\n",
       "      <td>0.218769</td>\n",
       "      <td>2.040615</td>\n",
       "      <td>0.433516</td>\n",
       "      <td>-0.190422</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>1.294439</td>\n",
       "      <td>0.635720</td>\n",
       "      <td>-1.114369</td>\n",
       "      <td>1.191932</td>\n",
       "      <td>-0.393770</td>\n",
       "      <td>-0.703637</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>1.298512</td>\n",
       "      <td>0.183781</td>\n",
       "      <td>-1.269311</td>\n",
       "      <td>1.519797</td>\n",
       "      <td>-0.476358</td>\n",
       "      <td>0.360044</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1.316507</td>\n",
       "      <td>0.194651</td>\n",
       "      <td>-1.155577</td>\n",
       "      <td>1.777353</td>\n",
       "      <td>-0.794331</td>\n",
       "      <td>-0.748294</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>686 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5  target\n",
       "0    1.210467  0.262052 -0.367110  1.045168 -0.385329 -0.685348     0.0\n",
       "1    1.418842  0.518833 -1.023205  1.438368  0.205112 -0.539704     0.0\n",
       "2    0.623524  0.588470 -0.410550  1.551780  0.218564 -0.442690     1.0\n",
       "3    1.337595  0.894654 -1.002048  0.903907  0.279202 -0.834362     1.0\n",
       "4    1.294439  0.635720 -1.114369  1.191932 -0.393770 -0.703637     0.0\n",
       "..        ...       ...       ...       ...       ...       ...     ...\n",
       "681  1.334870  0.145165 -0.275946  1.291604  0.213553 -0.521416     0.0\n",
       "682  0.593154 -0.358526  0.218769  2.040615  0.433516 -0.190422     1.0\n",
       "683  1.294439  0.635720 -1.114369  1.191932 -0.393770 -0.703637     1.0\n",
       "684  1.298512  0.183781 -1.269311  1.519797 -0.476358  0.360044     0.0\n",
       "685  1.316507  0.194651 -1.155577  1.777353 -0.794331 -0.748294     1.0\n",
       "\n",
       "[686 rows x 7 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Principal Component Analysis\n",
    "\n",
    "# Convert feature set to numpy array\n",
    "lamb = lambda x: 1. if x == True else 0.\n",
    "labels = dataset['target'].map(lamb).to_numpy()\n",
    "feature_set = dataset.drop(['target'], axis=1).applymap(lamb).to_numpy()\n",
    "\n",
    "# Calculate eigenvectors of covariance matrix\n",
    "C = np.cov(feature_set.T)\n",
    "evals, evecs = np.linalg.eig(C)\n",
    "pcts = 100 * evals / np.sum(evals)\n",
    "\n",
    "# Select Feature Matrix\n",
    "sortidx = np.argsort(pcts)\n",
    "sorted_evecs = evecs[sortidx[::-1]]\n",
    "feature_vec = sorted_evecs[:6]\n",
    "\n",
    "X_pca = feature_vec @ feature_set.T\n",
    "feature_vec.shape, np.sum(pcts[sortidx[::-1]][:6]), X_pca.shape\n",
    "tmp_df = pd.DataFrame(X_pca.T)\n",
    "tmp_df['target'] = labels\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "37c04e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.19474786, 0.17837407, 0.12973571, 0.12037835, 0.11731966,\n",
       "        0.09319146]),\n",
       " (686, 6))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "lamb = lambda x: 1. if x == True else 0.\n",
    "labels = dataset['target'].map(lamb).to_numpy()\n",
    "feature_set = dataset.drop(['target'], axis=1).applymap(lamb).to_numpy()\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "#X_scaled = scaler.fit_transform(feature_set)\n",
    "X_scaled = feature_set\n",
    "\n",
    "# Select the top n principal components\n",
    "n_components = 6\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "tmp_df = pd.DataFrame(X_pca)\n",
    "tmp_df['target'] = labels\n",
    "pca.explained_variance_ratio_, X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "83316443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delineate between traning and testing set\n",
    "train_df, test_df = train_test_split(tmp_df, test_size=0.2, random_state=42)\n",
    "y_train = train_df['target'].to_numpy()\n",
    "x_train = train_df.drop(['target'], axis=1).to_numpy()\n",
    "\n",
    "y_test = test_df['target'].to_numpy()\n",
    "x_test = test_df.drop(['target'], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d969036f",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier using Newton's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4019937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis function... sigmoid function\n",
    "def g(theta, x):\n",
    "    return 1 / (1 + np.exp(-x @ theta))\n",
    "\n",
    "# matrix derivative\n",
    "def dJ(theta, x, y):\n",
    "    m, _ = x.shape\n",
    "    return 1/m* x.T @ (g(theta, x) - y)\n",
    "\n",
    "# hessian matrix\n",
    "def HJ(theta, x):\n",
    "    m, _ = x.shape\n",
    "    Z = g(theta, x)\n",
    "    Z = Z*(1-Z)\n",
    "    return 1/m * Z * x.T @ x\n",
    "\n",
    "# distance between two vectors\n",
    "def dist(x, y):\n",
    "    return np.sum(np.abs(x-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb794e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    def __init__(self, step_size=0.2, max_iter=100, eps=1e-5,\n",
    "                theta_0=None, verbose=True):\n",
    "        self.theta = theta_0\n",
    "        self.step_size = step_size\n",
    "        self.max_iter = max_iter\n",
    "        self.eps = eps\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        m, n = x.shape\n",
    "        if self.theta is None:\n",
    "            self.theta=np.zeros(n)\n",
    "        for i in range(self.max_iter):\n",
    "            theta_new = self.theta - np.linalg.inv(HJ(self.theta, x)) @ dJ(self.theta, x, y)\n",
    "            if dist(theta_new, self.theta) < self.eps:\n",
    "                self.theta = theta_new\n",
    "                break\n",
    "            else:\n",
    "                self.theta = theta_new\n",
    "\n",
    "    def predict(self, x):\n",
    "        return x @ self.theta >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c4ca8375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta:  [-0.53279372  0.48695175  0.17197836  0.72416349  0.17035942  0.07462808]\n",
      "Training accuracy:  0.5894160583941606\n",
      "Testing accuracy:   0.5869565217391305\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(x_train, y_train)\n",
    "print(\"Theta: \", lg.theta)\n",
    "print(\"Training accuracy: \", np.mean(lg.predict(x_train) == y_train))\n",
    "print(\"Testing accuracy:  \", np.mean(lg.predict(x_test) == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a589d1",
   "metadata": {},
   "source": [
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f652b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Naive Bayes Classifier\n",
    "'''\n",
    "class NaiveBayes:\n",
    "    '''\n",
    "    Naive Bayes Classifier (Bernoulli event model)\n",
    "\n",
    "    During training, the classifier learns probabilities by counting the\n",
    "    occurences of feature/label combinations that it finds in the\n",
    "    training data. During prediction, it uses these counts to\n",
    "    compute probabilities.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, use_laplace_add_one):\n",
    "        self.label_counts = {}\n",
    "        self.feature_counts = {}\n",
    "        self.use_laplace_add_one = use_laplace_add_one # True for Laplace add-one smoothing\n",
    "\n",
    "    def fit(self, train_features, train_labels):\n",
    "        '''Training stage - learn from data'''\n",
    "\n",
    "        self.label_counts[0] = 0\n",
    "        self.label_counts[1] = 0\n",
    "\n",
    "        ### YOUR CODE HERE (~5-10 Lines)\n",
    "        self.label_counts[0] = np.count_nonzero(train_labels == 0)\n",
    "        self.label_counts[1] = np.count_nonzero(train_labels == 1)\n",
    "\n",
    "        for row, sample in enumerate(train_features):\n",
    "            label = train_labels[row]\n",
    "            for feature, feature_value in enumerate(sample):\n",
    "                key = (feature, feature_value, label)\n",
    "                self.feature_counts[key] = self.feature_counts.get(key, 0) + 1\n",
    "        ### END YOUR CODE\n",
    "\n",
    "    def predict(self, test_features):\n",
    "        '''Testing stage - classify new data'''\n",
    "\n",
    "        preds = np.zeros(test_features.shape[0], dtype=np.uint8)\n",
    "\n",
    "        tot = self.label_counts[0] + self.label_counts[1]\n",
    "        ### YOUR CODE HERE (~10-30 Lines)\n",
    "        p_y0 = self.label_counts[0] / tot\n",
    "        p_y1 = self.label_counts[1] / tot\n",
    "        for row, sample in enumerate(test_features):\n",
    "            p_y0_mid_x = p_y0\n",
    "            p_y1_mid_x = p_y1\n",
    "            for feature, feature_value in enumerate(sample):\n",
    "                #calc prob sample 0\n",
    "                xi = (feature, feature_value, 0)\n",
    "                c_xi_and_y0 = self.feature_counts.get(xi, 0)\n",
    "\n",
    "                #calc prob sample 1 \n",
    "                xi = (feature, feature_value, 1)\n",
    "                c_xi_and_y1 = self.feature_counts.get(xi, 0)\n",
    "\n",
    "                if (self.use_laplace_add_one):\n",
    "                    p_y0_mid_x *= (c_xi_and_y0 + 1) / (self.label_counts[0] + 2)\n",
    "                    p_y1_mid_x *= (c_xi_and_y1 + 1) / (self.label_counts[1] + 2)\n",
    "                else:\n",
    "                    p_y0_mid_x *= (c_xi_and_y0 / self.label_counts[0])\n",
    "                    p_y1_mid_x *= (c_xi_and_y1 / self.label_counts[1])\n",
    "\n",
    "            #calculate argmax\n",
    "            if (p_y0_mid_x > p_y1_mid_x):\n",
    "                preds[row] = 0\n",
    "            else:\n",
    "                preds[row] = 1 \n",
    "        ### END YOUR CODE\n",
    "\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35b30389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.7208029197080292\n",
      "Testing accuracy:   0.5362318840579711\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes(True)\n",
    "nb.fit(x_train, y_train)\n",
    "print(\"Training accuracy: \", np.mean(nb.predict(x_train) == y_train))\n",
    "print(\"Testing accuracy:  \", np.mean(nb.predict(x_test) == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "54c9511e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.7135036496350365\n",
      "Testing accuracy:   0.5434782608695652\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes(True)\n",
    "nb.fit(x_train, y_train)\n",
    "print(\"Training accuracy: \", np.mean(nb.predict(x_train) == y_train))\n",
    "print(\"Testing accuracy:  \", np.mean(nb.predict(x_test) == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3b9260",
   "metadata": {},
   "source": [
    "### scikit-learn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a5a91836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.7171532846715328\n",
      "Testing accuracy:   0.5652173913043478\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "tree_clf = tree.DecisionTreeClassifier()\n",
    "tree_clf.fit(x_train, y_train)\n",
    "print(\"\")\n",
    "print(\"Training accuracy: \", np.mean(tree_clf.predict(x_train) == y_train))\n",
    "print(\"Testing accuracy:  \", np.mean(tree_clf.predict(x_test) == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c6355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree_clf = tree.DecisionTreeClassifier()\n",
    "tree_clf.fit(x_train, y_train)\n",
    "print(\"Training accuracy: \", np.mean(tree_clf.predict(x_train) == y_train))\n",
    "print(\"Testing accuracy:  \", np.mean(tree_clf.predict(x_test) == y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
