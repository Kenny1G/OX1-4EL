{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50ff06d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import collections\n",
    "import re, string\n",
    "import sys\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82280ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "def init_dataset(json) -> tuple[dict, list]:\n",
    "    ds: dict = {}\n",
    "    keys = json.keys()\n",
    "    for k in keys:\n",
    "        ds[k] = []\n",
    "    return ds, keys\n",
    "\n",
    "def read_json(file) -> pd.DataFrame:\n",
    "    dataset = {}\n",
    "    keys = []\n",
    "    with open(file) as file_lines:\n",
    "        for count, line in enumerate(file_lines):\n",
    "            json_line = json.loads(line.strip())\n",
    "            if count == 0:\n",
    "                dataset, keys = init_dataset(json_line)\n",
    "            for k in keys:\n",
    "                dataset[k].append(json_line[k])\n",
    "        return pd.DataFrame(dataset)\n",
    "\n",
    "def read_csv(file) -> pd.DataFrame:\n",
    "    dataset = {}\n",
    "    with open(file, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        keys = reader.fieldnames\n",
    "        for k in keys:\n",
    "            dataset[k] = []\n",
    "        for row in reader:\n",
    "            for k in keys:\n",
    "                dataset[k].append(row[k])\n",
    "    return pd.DataFrame(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc0257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yelp_review = read_json('data/yelp_academic_dataset_review.json')\n",
    "yelp_review = read_csv('data/yelp_academic_dataset_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02e0a185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yelp_business = read_json('data/yelp_academic_dataset_business.json')\n",
    "yelp_business = read_csv('data/yelp_academic_dataset_business.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd32bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data: Restaurants reviewed by karen, the user with the most reviews\n",
    "# Businesses that are categorized as restaurants\n",
    "business_restaurant = yelp_business.loc[yelp_business['categories'].str.contains('Restaurant', na=False)]\n",
    "# Reviews of Restaurant businesses\n",
    "review_restaurant = yelp_review[yelp_review['business_id'].isin(business_restaurant['business_id'])]\n",
    "# User with most restaurant reviews\n",
    "karen = review_restaurant['user_id'].value_counts().index[0]\n",
    "# Reviews Karen has made of restaurant businesses\n",
    "review_restaurant_karen = review_restaurant.loc[review_restaurant['user_id'] == karen]\n",
    "# Restaurant businesses that Karen has reviewed\n",
    "business_restaurant_karen = business_restaurant[business_restaurant['business_id'].isin(review_restaurant_karen['business_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b52787",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean Data: remove missing rows and irrelevant columns\n",
    "df = business_restaurant_karen.set_index('business_id')\n",
    "\n",
    "# Remove columns with greater than 20% missing fields\n",
    "mask = df.applymap(lambda x: x =='' or x == 'None').sum()\n",
    "features = ((mask/len(df)) * 100).map(lambda x: x < 20)\n",
    "\n",
    "\n",
    "# Remove non-attribute columns (except business_id)\n",
    "features.loc[~features.index.str.contains('attributes.')] = False\n",
    "#features.loc['business_id'] = True\n",
    "dataset = df.loc[:, features]\n",
    "\n",
    "# Remove rows with missing data\n",
    "mask = dataset.applymap(lambda x: x == '' or x == 'None')\n",
    "dataset = dataset.loc[~mask.any(axis=1)]\n",
    "\n",
    "# Remove all non-boolean columns\n",
    "mask = dataset.applymap(lambda x : x == 'True' or x == 'False').sum() != 0\n",
    "#mask.loc['business_id'] = True\n",
    "#dataset = dataset.set_index('business_id')\n",
    "dataset = dataset.loc[:, mask].applymap(lambda x: x == 'True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ebaeb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Data: add targets\n",
    "df = review_restaurant_karen.set_index('business_id')\n",
    "df = df.loc[df.index.intersection(dataset.index)]\n",
    "df = df.astype({'stars':'float'})\n",
    "dataset['target'] = df.groupby(df.index)['stars'].mean().map(lambda x: x > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f25b3284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delineate between traning and testing set\n",
    "train_df, test_df = train_test_split(dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d969036f",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier using Newton's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ef3e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "\n",
    "lamb = lambda x: 1. if x == True else 0.\n",
    "y_train = train_df['target'].map(lamb).to_numpy()\n",
    "x_train = train_df.drop(['target'], axis=1).applymap(lamb).to_numpy()\n",
    "\n",
    "y_test = test_df['target'].map(lamb).to_numpy()\n",
    "x_test = test_df.drop(['target'], axis=1).applymap(lamb).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4019937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis function... sigmoid function\n",
    "def g(theta, x):\n",
    "    return 1 / (1 + np.exp(-x @ theta))\n",
    "\n",
    "# matrix derivative\n",
    "def dJ(theta, x, y):\n",
    "    m, _ = x.shape\n",
    "    return 1/m* x.T @ (g(theta, x) - y)\n",
    "\n",
    "# hessian matrix\n",
    "def HJ(theta, x):\n",
    "    m, _ = x.shape\n",
    "    Z = g(theta, x)\n",
    "    Z = Z*(1-Z)\n",
    "    return 1/m * Z * x.T @ x\n",
    "\n",
    "# distance between two vectors\n",
    "def dist(x, y):\n",
    "    return np.sum(np.abs(x-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb794e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    def __init__(self, step_size=0.2, max_iter=100, eps=1e-5,\n",
    "                theta_0=None, verbose=True):\n",
    "        self.theta = theta_0\n",
    "        self.step_size = step_size\n",
    "        self.max_iter = max_iter\n",
    "        self.eps = eps\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        m, n = x.shape\n",
    "        if self.theta is None:\n",
    "            self.theta=np.zeros(n)\n",
    "        for i in range(self.max_iter):\n",
    "            theta_new = self.theta - np.linalg.inv(HJ(self.theta, x)) @ dJ(self.theta, x, y)\n",
    "            if dist(theta_new, self.theta) < self.eps:\n",
    "                self.theta = theta_new\n",
    "                break\n",
    "            else:\n",
    "                self.theta = theta_new\n",
    "\n",
    "    def predict(self, x):\n",
    "        return x @ self.theta >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4ca8375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta:  [ 0.59714209  0.49508892 -0.042109   -0.08595731  0.51446855 -0.48017102\n",
      "  0.13016552 -0.64661731 -0.19983955  0.52538337]\n",
      "Training accuracy:  0.6076642335766423\n",
      "Testing accuracy:   0.6014492753623188\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(x_train, y_train)\n",
    "print(\"Theta: \", lg.theta)\n",
    "print(\"Training accuracy: \", np.mean(lg.predict(x_train) == y_train))\n",
    "print(\"Testing accuracy:  \", np.mean(lg.predict(x_test) == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a589d1",
   "metadata": {},
   "source": [
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f652b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Naive Bayes Classifier\n",
    "'''\n",
    "class NaiveBayes:\n",
    "    '''\n",
    "    Naive Bayes Classifier (Bernoulli event model)\n",
    "\n",
    "    During training, the classifier learns probabilities by counting the\n",
    "    occurences of feature/label combinations that it finds in the\n",
    "    training data. During prediction, it uses these counts to\n",
    "    compute probabilities.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, use_laplace_add_one):\n",
    "        self.label_counts = {}\n",
    "        self.feature_counts = {}\n",
    "        self.use_laplace_add_one = use_laplace_add_one # True for Laplace add-one smoothing\n",
    "\n",
    "    def fit(self, train_features, train_labels):\n",
    "        '''Training stage - learn from data'''\n",
    "\n",
    "        self.label_counts[0] = 0\n",
    "        self.label_counts[1] = 0\n",
    "\n",
    "        ### YOUR CODE HERE (~5-10 Lines)\n",
    "        self.label_counts[0] = np.count_nonzero(train_labels == 0)\n",
    "        self.label_counts[1] = np.count_nonzero(train_labels == 1)\n",
    "\n",
    "        for row, sample in enumerate(train_features):\n",
    "            label = train_labels[row]\n",
    "            for feature, feature_value in enumerate(sample):\n",
    "                key = (feature, feature_value, label)\n",
    "                self.feature_counts[key] = self.feature_counts.get(key, 0) + 1\n",
    "        ### END YOUR CODE\n",
    "\n",
    "    def predict(self, test_features):\n",
    "        '''Testing stage - classify new data'''\n",
    "\n",
    "        preds = np.zeros(test_features.shape[0], dtype=np.uint8)\n",
    "\n",
    "        tot = self.label_counts[0] + self.label_counts[1]\n",
    "        ### YOUR CODE HERE (~10-30 Lines)\n",
    "        p_y0 = self.label_counts[0] / tot\n",
    "        p_y1 = self.label_counts[1] / tot\n",
    "        for row, sample in enumerate(test_features):\n",
    "            p_y0_mid_x = p_y0\n",
    "            p_y1_mid_x = p_y1\n",
    "            for feature, feature_value in enumerate(sample):\n",
    "                #calc prob sample 0\n",
    "                xi = (feature, feature_value, 0)\n",
    "                c_xi_and_y0 = self.feature_counts.get(xi, 0)\n",
    "\n",
    "                #calc prob sample 1 \n",
    "                xi = (feature, feature_value, 1)\n",
    "                c_xi_and_y1 = self.feature_counts.get(xi, 0)\n",
    "\n",
    "                if (self.use_laplace_add_one):\n",
    "                    p_y0_mid_x *= (c_xi_and_y0 + 1) / (self.label_counts[0] + 2)\n",
    "                    p_y1_mid_x *= (c_xi_and_y1 + 1) / (self.label_counts[1] + 2)\n",
    "                else:\n",
    "                    p_y0_mid_x *= (c_xi_and_y0 / self.label_counts[0])\n",
    "                    p_y1_mid_x *= (c_xi_and_y1 / self.label_counts[1])\n",
    "\n",
    "            #calculate argmax\n",
    "            if (p_y0_mid_x > p_y1_mid_x):\n",
    "                preds[row] = 0\n",
    "            else:\n",
    "                preds[row] = 1 \n",
    "        ### END YOUR CODE\n",
    "\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35b30389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.6113138686131386\n",
      "Testing accuracy:   0.6014492753623188\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes(True)\n",
    "nb.fit(x_train, y_train)\n",
    "print(\"Training accuracy: \", np.mean(nb.predict(x_train) == y_train))\n",
    "print(\"Testing accuracy:  \", np.mean(nb.predict(x_test) == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558f94d2",
   "metadata": {},
   "source": [
    "### Logistic Regression using gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "259747f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Logistic Regression Classifier\n",
    "'''\n",
    "class LogisticRegression2:\n",
    "    '''\n",
    "    Logistic Regression Classifier\n",
    "\n",
    "    During training, Logistic Regression learns weights for each\n",
    "    feature using gradient ascent. During prediction, it uses\n",
    "    the test data to apply a linear transformation to the weights,\n",
    "    obtaining a probability for each example in the test data.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, learning_rate, max_steps):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_steps = max_steps\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, train_features, train_labels):\n",
    "        '''Training stage - learn from data'''\n",
    "\n",
    "        # This line inserts a column of ones before the first column of train_features,\n",
    "        # resulting in the an `n x (d + 1)` size matrix, This is so we\n",
    "        # don't need to have a special case for the bias weight.\n",
    "        train_features = np.insert(train_features, 0, 1, axis=1)\n",
    "\n",
    "        # This makes the matrix immutable\n",
    "        train_features.setflags(write=False)\n",
    "\n",
    "        # This is the theta you will be performing gradient ascent on. It has\n",
    "        # shape (d + 1).\n",
    "        theta = np.zeros(train_features.shape[1])\n",
    "\n",
    "        ### YOUR CODE HERE (~3-10 Lines)\n",
    "        for _ in range(self.max_steps):\n",
    "            gradients = np.zeros(train_features.shape[1])\n",
    "            for y, x in enumerate(train_features):\n",
    "                gradients += x * (train_labels[y] - sigmoid(theta @ x))\n",
    "            theta += self.learning_rate * gradients\n",
    "        ### END YOUR CODE\n",
    "\n",
    "        self.weights = theta\n",
    "\n",
    "    def predict(self, test_features):\n",
    "        '''Testing stage - classify new data'''\n",
    "\n",
    "        test_features = np.insert(test_features, 0, 1, axis=1) # add bias term\n",
    "        test_features.setflags(write=False) # make immutable\n",
    "        preds = np.zeros(test_features.shape[0], np.uint8)\n",
    "\n",
    "        ### YOUR CODE HERE (~1-7 Lines)\n",
    "        preds = np.where(sigmoid(test_features @ self.weights) > 0.5, 1, 0)\n",
    "        ### END YOUR CODE\n",
    "\n",
    "        return preds\n",
    "\n",
    "def sigmoid(vec):\n",
    "    '''Numerically stable implementation of the sigmoid function'''\n",
    "    positive_mask = vec >= 0\n",
    "    negative_mask = vec < 0\n",
    "    exp = np.zeros_like(vec, dtype=np.float64)\n",
    "    exp[positive_mask] = np.exp(-vec[positive_mask])\n",
    "    exp[negative_mask] = np.exp(vec[negative_mask])\n",
    "    top = np.ones_like(vec, dtype=np.float64)\n",
    "    top[negative_mask] = exp[negative_mask]\n",
    "    return top / (1 + exp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "786a9ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.4397810218978102\n",
      "Testing accuracy:   0.43478260869565216\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression2(0.2, 100)\n",
    "lg.fit(x_train, y_train)\n",
    "#print(\"Theta: \", lg.theta)\n",
    "print(\"Training accuracy: \", np.mean(lg.predict(x_train) == y_train))\n",
    "print(\"Testing accuracy:  \", np.mean(lg.predict(x_test) == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ace04",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data_host/SAMPLES', exist_ok=True)\n",
    "# review_restaurant_karen.to_csv('data_host/SAMPLES/review_restaurant_karen.csv')\n",
    "# business_restaurant_karen.to_csv('data_host/SAMPLES/business_restaurant_karen.csv')\n",
    "dataset = dataset.applymap(lambda x: 1 if x == True else 0)\n",
    "dataset.to_csv('data_host/SAMPLES/dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
