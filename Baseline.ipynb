{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50ff06d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import collections\n",
    "import re, string\n",
    "import sys\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82280ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "def init_dataset(json) -> tuple[dict, list]:\n",
    "    ds: dict = {}\n",
    "    keys = json.keys()\n",
    "    for k in keys:\n",
    "        ds[k] = []\n",
    "    return ds, keys\n",
    "\n",
    "def read_json(file) -> pd.DataFrame:\n",
    "    dataset = {}\n",
    "    keys = []\n",
    "    with open(file) as file_lines:\n",
    "        for count, line in enumerate(file_lines):\n",
    "            json_line = json.loads(line.strip())\n",
    "            if count == 0:\n",
    "                dataset, keys = init_dataset(json_line)\n",
    "            for k in keys:\n",
    "                dataset[k].append(json_line[k])\n",
    "        return pd.DataFrame(dataset)\n",
    "\n",
    "def read_csv(file) -> pd.DataFrame:\n",
    "    dataset = {}\n",
    "    with open(file, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        keys = reader.fieldnames\n",
    "        for k in keys:\n",
    "            dataset[k] = []\n",
    "        for row in reader:\n",
    "            for k in keys:\n",
    "                dataset[k].append(row[k])\n",
    "    return pd.DataFrame(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc0257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yelp_review = read_json('data/yelp_academic_dataset_review.json')\n",
    "yelp_review = read_csv('data/yelp_academic_dataset_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02e0a185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yelp_business = read_json('data/yelp_academic_dataset_business.json')\n",
    "yelp_business = read_csv('data/yelp_academic_dataset_business.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd32bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data: Restaurants reviewed by karen, the user with the most reviews\n",
    "# Businesses that are categorized as restaurants\n",
    "business_restaurant = yelp_business.loc[yelp_business['categories'].str.contains('Restaurant', na=False)]\n",
    "# Reviews of Restaurant businesses\n",
    "review_restaurant = yelp_review[yelp_review['business_id'].isin(business_restaurant['business_id'])]\n",
    "# User with most restaurant reviews\n",
    "karen = review_restaurant['user_id'].value_counts().index[0]\n",
    "# Reviews Karen has made of restaurant businesses\n",
    "review_restaurant_karen = review_restaurant.loc[review_restaurant['user_id'] == karen]\n",
    "# Restaurant businesses that Karen has reviewed\n",
    "business_restaurant_karen = business_restaurant[business_restaurant['business_id'].isin(review_restaurant_karen['business_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b52787",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean Data: remove missing rows and irrelevant columns\n",
    "df = business_restaurant_karen.set_index('business_id')\n",
    "\n",
    "# Remove columns with greater than 20% missing fields\n",
    "mask = df.applymap(lambda x: x =='' or x == 'None').sum()\n",
    "features = ((mask/len(df)) * 100).map(lambda x: x < 20)\n",
    "\n",
    "\n",
    "# Remove non-attribute columns (except business_id)\n",
    "features.loc[~features.index.str.contains('attributes.')] = False\n",
    "#features.loc['business_id'] = True\n",
    "dataset = df.loc[:, features]\n",
    "\n",
    "# Remove rows with missing data\n",
    "mask = dataset.applymap(lambda x: x == '' or x == 'None')\n",
    "dataset = dataset.loc[~mask.any(axis=1)]\n",
    "\n",
    "# Remove all non-boolean columns\n",
    "mask = dataset.applymap(lambda x : x == 'True' or x == 'False').sum() != 0\n",
    "#mask.loc['business_id'] = True\n",
    "#dataset = dataset.set_index('business_id')\n",
    "dataset = dataset.loc[:, mask].applymap(lambda x: x == 'True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ebaeb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Data: add targets\n",
    "df = review_restaurant_karen.set_index('business_id')\n",
    "df = df.loc[df.index.intersection(dataset.index)]\n",
    "df = df.astype({'stars':'float'})\n",
    "dataset['target'] = df.groupby(df.index)['stars'].mean().map(lambda x: x > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f25b3284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delineate between traning and testing set\n",
    "train_df, test_df = train_test_split(dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d969036f",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier using Newton's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3ef3e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "\n",
    "lamb = lambda x: 1. if x == True else 0.\n",
    "y_train = train_df['target'].map(lamb).to_numpy()\n",
    "x_train = train_df.drop(['target'], axis=1).applymap(lamb).to_numpy()\n",
    "\n",
    "y_test = test_df['target'].map(lamb).to_numpy()\n",
    "x_test = test_df.drop(['target'], axis=1).applymap(lamb).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e4019937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis function... sigmoid function\n",
    "def g(theta, x):\n",
    "    return 1 / (1 + np.exp(-x @ theta))\n",
    "\n",
    "# matrix derivative\n",
    "def dJ(theta, x, y):\n",
    "    m, _ = x.shape\n",
    "    return 1/m* x.T @ (g(theta, x) - y)\n",
    "\n",
    "# hessian matrix\n",
    "def HJ(theta, x):\n",
    "    m, _ = x.shape\n",
    "    Z = g(theta, x)\n",
    "    Z = Z*(1-Z)\n",
    "    return 1/m * Z * x.T @ x\n",
    "\n",
    "# distance between two vectors\n",
    "def dist(x, y):\n",
    "    return np.sum(np.abs(x-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cb794e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    def __init__(self, step_size=0.2, max_iter=100, eps=1e-5,\n",
    "                theta_0=None, verbose=True):\n",
    "        self.theta = theta_0\n",
    "        self.step_size = step_size\n",
    "        self.max_iter = max_iter\n",
    "        self.eps = eps\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        m, n = x.shape\n",
    "        if self.theta is None:\n",
    "            self.theta=np.zeros(n)\n",
    "        for i in range(self.max_iter):\n",
    "            theta_new = self.theta - np.linalg.inv(HJ(self.theta, x)) @ dJ(self.theta, x, y)\n",
    "            if dist(theta_new, self.theta) < self.eps:\n",
    "                self.theta = theta_new\n",
    "                break\n",
    "            else:\n",
    "                self.theta = theta_new\n",
    "\n",
    "    def predict(self, x):\n",
    "        return x @ self.theta >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c4ca8375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta:  [ 0.59714209  0.49508892 -0.042109   -0.08595731  0.51446855 -0.48017102\n",
      "  0.13016552 -0.64661731 -0.19983955  0.52538337]\n",
      "Training accuracy:  0.6076642335766423\n",
      "Testing accuracy:   0.6014492753623188\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(x_train, y_train)\n",
    "print(\"Theta: \", lg.theta)\n",
    "print(\"Training accuracy: \", np.mean(lg.predict(x_train) == y_train))\n",
    "print(\"Testing accuracy:  \", np.mean(lg.predict(x_test) == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c40ace04",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data_host/SAMPLES', exist_ok=True)\n",
    "# review_restaurant_karen.to_csv('data_host/SAMPLES/review_restaurant_karen.csv')\n",
    "# business_restaurant_karen.to_csv('data_host/SAMPLES/business_restaurant_karen.csv')\n",
    "dataset = dataset.applymap(lambda x: 1 if x == True else 0)\n",
    "dataset.to_csv('data_host/SAMPLES/dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
